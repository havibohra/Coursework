{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ques 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis (LDA):\n",
      "Train Misclassification Rate: 0.0296\n",
      "Test Misclassification Rate: 0.0000\n",
      "\n",
      "Quadratic Discriminant Analysis (QDA):\n",
      "Train Misclassification Rate: 0.0370\n",
      "Test Misclassification Rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Part (a): Linear and Quadratic Discriminant Analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "iris_data = pd.read_csv('iris.csv')\n",
    "\n",
    "# Split data into features and target\n",
    "X = iris_data.drop(columns=['Species_name'])  # Features\n",
    "y = iris_data['Species_name']  # Target\n",
    "\n",
    "# Split the dataset into training (90%) and test (10%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "y_pred_lda_train = lda.predict(X_train)\n",
    "y_pred_lda_test = lda.predict(X_test)\n",
    "\n",
    "# Quadratic Discriminant Analysis (QDA)\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred_qda_train = qda.predict(X_train)\n",
    "y_pred_qda_test = qda.predict(X_test)\n",
    "\n",
    "# Print misclassification rates\n",
    "print(\"Linear Discriminant Analysis (LDA):\")\n",
    "print(f\"Train Misclassification Rate: {1 - accuracy_score(y_train, y_pred_lda_train):.4f}\")\n",
    "print(f\"Test Misclassification Rate: {1 - accuracy_score(y_test, y_pred_lda_test):.4f}\")\n",
    "\n",
    "print(\"\\nQuadratic Discriminant Analysis (QDA):\")\n",
    "print(f\"Train Misclassification Rate: {1 - accuracy_score(y_train, y_pred_qda_train):.4f}\")\n",
    "print(f\"Test Misclassification Rate: {1 - accuracy_score(y_test, y_pred_qda_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bayes Classifier using KDE:\n",
      "Train Misclassification Rate: 0.0000\n",
      "Test Misclassification Rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Part (b): Bayes Classifier using Kernel Density Estimation\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# KDE-based Bayes Classifier\n",
    "def kde_bayes_classifier(X_train, y_train, X_test, bandwidth=1.0):\n",
    "    classes = y_train.unique()\n",
    "    priors = {cls: (y_train == cls).mean() for cls in classes}\n",
    "    densities = {}\n",
    "    \n",
    "    for cls in classes:\n",
    "        kde = KernelDensity(bandwidth=bandwidth)\n",
    "        kde.fit(X_train[y_train == cls])\n",
    "        densities[cls] = kde\n",
    "\n",
    "    def predict(X):\n",
    "        log_probs = {cls: densities[cls].score_samples(X) + np.log(priors[cls]) for cls in classes}\n",
    "        return np.array([max(log_probs, key=lambda k: log_probs[k][i]) for i in range(X.shape[0])])\n",
    "\n",
    "    return predict(X_test)\n",
    "\n",
    "# Predict with KDE-based Bayes Classifier\n",
    "y_pred_kde_train = kde_bayes_classifier(X_train, y_train, X_train)\n",
    "y_pred_kde_test = kde_bayes_classifier(X_train, y_train, X_test)\n",
    "\n",
    "# Print misclassification rates\n",
    "print(\"\\nBayes Classifier using KDE:\")\n",
    "print(f\"Train Misclassification Rate: {1 - accuracy_score(y_train, y_pred_kde_train):.4f}\")\n",
    "print(f\"Test Misclassification Rate: {1 - accuracy_score(y_test, y_pred_kde_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ques 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis (LDA):\n",
      "Train Misclassification Rate: 0.0000\n",
      "Test Misclassification Rate: 0.0000\n",
      "\n",
      "Quadratic Discriminant Analysis (QDA):\n",
      "Train Misclassification Rate: 0.0062\n",
      "Test Misclassification Rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Part (a): Linear and Quadratic Discriminant Analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "wine_data = pd.read_csv('wine_italy.csv')\n",
    "\n",
    "# Split data into features and target\n",
    "X = wine_data.drop(columns=['Type'])  # Replace 'Class' with actual target column name\n",
    "y = wine_data['Type']\n",
    "\n",
    "# Split the dataset into training (90%) and test (10%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "lda = LinearDiscriminantAnalysis()  # Priors are estimated by default\n",
    "lda.fit(X_train, y_train)\n",
    "y_pred_lda_train = lda.predict(X_train)\n",
    "y_pred_lda_test = lda.predict(X_test)\n",
    "\n",
    "# Quadratic Discriminant Analysis (QDA)\n",
    "qda = QuadraticDiscriminantAnalysis()  # Priors are estimated by default\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred_qda_train = qda.predict(X_train)\n",
    "y_pred_qda_test = qda.predict(X_test)\n",
    "\n",
    "# Print misclassification rates\n",
    "print(\"Linear Discriminant Analysis (LDA):\")\n",
    "print(f\"Train Misclassification Rate: {1 - accuracy_score(y_train, y_pred_lda_train):.4f}\")\n",
    "print(f\"Test Misclassification Rate: {1 - accuracy_score(y_test, y_pred_lda_test):.4f}\")\n",
    "\n",
    "print(\"\\nQuadratic Discriminant Analysis (QDA):\")\n",
    "print(f\"Train Misclassification Rate: {1 - accuracy_score(y_train, y_pred_qda_train):.4f}\")\n",
    "print(f\"Test Misclassification Rate: {1 - accuracy_score(y_test, y_pred_qda_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bayes Classifier using KDE:\n",
      "Train Misclassification Rate: 0.0000\n",
      "Test Misclassification Rate: 0.2222\n"
     ]
    }
   ],
   "source": [
    "# Part (b): Bayes Classifier using Kernel Density Estimation\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "wine_data = pd.read_csv('wine_italy.csv')\n",
    "\n",
    "# Split data into features and target\n",
    "X = wine_data.drop(columns=['Type'])  # Replace 'Class' with actual target column name\n",
    "y = wine_data['Type']\n",
    "\n",
    "# Split the dataset into training (90%) and test (10%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "# Define function for KDE-based Bayes Classifier\n",
    "def kde_bayes_classifier(X_train, y_train, X_test, bandwidth=1.0):\n",
    "    classes = y_train.unique()\n",
    "    priors = {cls: 1 / len(classes) for cls in classes}  # Equal priors\n",
    "    densities = {}\n",
    "    \n",
    "    for cls in classes:\n",
    "        kde = KernelDensity(bandwidth=bandwidth)\n",
    "        kde.fit(X_train[y_train == cls])\n",
    "        densities[cls] = kde\n",
    "\n",
    "    def predict(X):\n",
    "        log_probs = {cls: densities[cls].score_samples(X) + np.log(priors[cls]) for cls in classes}\n",
    "        return np.array([max(log_probs, key=lambda k: log_probs[k][i]) for i in range(X.shape[0])])\n",
    "\n",
    "    return predict(X_test)\n",
    "\n",
    "# Predict with KDE-based Bayes Classifier\n",
    "y_pred_kde_train = kde_bayes_classifier(X_train, y_train, X_train)\n",
    "y_pred_kde_test = kde_bayes_classifier(X_train, y_train, X_test)\n",
    "\n",
    "# Print misclassification rates\n",
    "print(\"\\nBayes Classifier using KDE:\")\n",
    "print(f\"Train Misclassification Rate: {1 - accuracy_score(y_train, y_pred_kde_train):.4f}\")\n",
    "print(f\"Test Misclassification Rate: {1 - accuracy_score(y_test, y_pred_kde_test):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
